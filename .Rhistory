projthis::proj_use_workflow("workflow", git_ignore_data = FALSE)
proj_workflow_use_rmd("00-import")
projthis::proj_workflow_use_rmd("00-import")
here::i_am(paste0(params$name, ".Rmd"), uuid = "c614387e-b8b5-49bd-a8ab-99ba8e026b90")
library(tidyverse)
library(readxl)
# create or *empty* the target directory, used to write this file's data:
projthis::proj_create_dir_target(params$name, clean = TRUE)
# function to get path to target directory: path_target("sample.csv")
path_target <- projthis::proj_path_target(params$name)
# function to get path to previous data: path_source("00-import", "sample.csv")
path_source <- projthis::proj_path_source(params$name)
write_family <- function(fam_id, complete_df, out_directory, suffix){
# Check if directory exists
if(!dir.exists(out_directory)){
# If it does not exist, create it
dir.create(out_directory, recursive = TRUE)
}
# Gather relevant data
family_df <- complete_df %>%
filter(Family == fam_id) %>%
# Order timepoint
mutate(time_posit = strptime(Time, format = "%m/%d/%Y %H:%M:%S", tz = "CET")) %>%
arrange(time_posit)
# Gather Plate ID
plate_id <- family_df %>%
select(Plate) %>%
unlist() %>%
unique()
# Get rid of uneeded data
family_df <- family_df %>%
select(-c(Family, Plate, time_posit))
# Write file
filename = paste0(plate_id, "_", suffix, ".tsv.gz")
complete.outfile <- file.path(out_directory, filename)
write_tsv(family_df, complete.outfile)
message(paste("Wrote", filename, "to", out_directory))
stopifnot(file.exists(complete.outfile))
}
process_logfile <- function(file_path, output_dir, timezone="CET", invert=T, Lux=T, batchname = NULL){
# Gather batchname and create subdirectory
if(is.null(batchname)){
batch_name <- str_split(file_path, "/")[[1]][4]
} else{
batch_name <- batchname %>%
filter(`SAMI file` == basename(file_path)) %>%
pull(batch) %>%
unique()
}
if(is.na(batch_name)){
print(basename(file.path))
}
# Read the raw logfile
dataset <- read.table(file_path, header=FALSE, sep="\t", na.strings="NA", dec=".", strip.white=TRUE, skip = 4)
# Remove empty columns and remove duplicated rows
dataset <- dataset %>%
select(where(function(x) any(!is.na(x)))) %>%
distinct()
# Assign new column names depending on inversion or no inversion
if(invert){
well_coords <- rev(paste0(rep(LETTERS[1:16], each=24),rep(seq(1,24), 16)))
} else{
well_coords <- paste0(rep(LETTERS[1:16], each=24),rep(seq(1,24), 16))
}
header <- c("Family","Plate","Time", well_coords)
stopifnot(length(header) == ncol(dataset))
colnames(dataset) <- header
# Separate Lux and OD data
if(Lux){
od_data <- dataset[seq(1, nrow(dataset), by=2),]
lux_data <- dataset[seq(2, nrow(dataset), by=2),]
stopifnot(nrow(od_data) == nrow(lux_data))
# Write separate files for od and lux per family
sapply(unique(od_data$Family), write_family, complete_df=od_data, out_directory=file.path(output_dir, "od_data", batch_name), suffix="OD")
sapply(unique(lux_data$Family), write_family, complete_df=lux_data, out_directory=file.path(output_dir, "lux_data", batch_name), suffix="LUX")
#return(list("od_data" = od_data, "lux_data" = lux_data))
}else{
return(dataset)
}
}
dir.create(path_target("Salmonella/od_data"), recursive = TRUE)
dir.create(path_target("Salmonella/lux_data"), recursive = TRUE)
plate_db <- read_excel("../RAW_DATA/Salmonella/PlateDatabase_OCT2023.xlsx")
write_tsv(file = path_target("Salmonella/PlateDatabase.tsv.gz"), x=plate_db)
libmap_df <- read_tsv("../RAW_DATA/Salmonella/LibMap.txt")
write_tsv(x=libmap_df, file = path_target("Salmonella/LibMap.tsv.gz"))
libmap_df <- read_tsv("../RAW_DATA/Salmonella/LibMap.txt", show_col_types = FALSE)
write_tsv(x=libmap_df, file = path_target("Salmonella/LibMap.tsv.gz"))
